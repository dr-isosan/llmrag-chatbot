import sqlite3
from datetime import datetime
import json

DB_PATH = "questions.db"

def init_db():
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("""
    CREATE TABLE IF NOT EXISTS questions (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        question TEXT NOT NULL,
        answer TEXT,
        source_file TEXT,
        source_keyword TEXT,
        topic TEXT,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    )
    """)
    
    # Mevcut tabloya topic sÃ¼tunu ekle (eÄŸer yoksa)
    try:
        c.execute("ALTER TABLE questions ADD COLUMN topic TEXT")
    except sqlite3.OperationalError:
        pass  # SÃ¼tun zaten varsa hata verme
    c.execute("""
    CREATE TABLE IF NOT EXISTS question_sources (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        question_id INTEGER,
        source_file TEXT,
        FOREIGN KEY(question_id) REFERENCES questions(id),
        UNIQUE(question_id, source_file)
    )
    """)
    c.execute("""
    CREATE TABLE IF NOT EXISTS question_similarity (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        question_id_1 INTEGER,
        question_id_2 INTEGER,
        similarity REAL,
        FOREIGN KEY(question_id_1) REFERENCES questions(id),
        FOREIGN KEY(question_id_2) REFERENCES questions(id)
    )
    """)
    c.execute("""
    CREATE TABLE IF NOT EXISTS user_sessions (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        user_id TEXT NOT NULL,
        session_date DATE DEFAULT (date('now')),
        first_visit TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        last_activity TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        total_questions INTEGER DEFAULT 0,
        UNIQUE(user_id, session_date)
    )
    """)
    conn.commit()
    conn.close()

def detect_topic(question):
    """Sorudan topic/konu tespit et"""
    question_lower = question.lower()
    
    # Konu tespit kurallarÄ±
    topics = {
        "bilgisayar_laboratuvari": ["bilgisayar laboratuvar", "lab", "laboratuvar", "sÄ±nav", "su getir", "yiyecek", "iÃ§ecek"],
        "eduroam": ["eduroam", "wifi", "internet", "baÄŸlantÄ±", "ÅŸifre", "parola", "android", "eap", "phase"],
        "sinav_kurallari": ["sÄ±nav", "kurall", "yapÄ±lacak", "yasaklÄ±", "izin"],
        "kimlik_belgesi": ["kimlik", "belge", "Ã¶ÄŸrenci kart", "tc kimlik"],
        "kayit_isleri": ["kayÄ±t", "ders", "kredi", "not", "transkript"],
        "yemek": ["yemek", "kafeterya", "mensa", "beslenme"],
        "konaklama": ["yurt", "barÄ±nma", "konaklama", "ev"],
        "ulasim": ["otobÃ¼s", "ulaÅŸÄ±m", "servis", "ring"],
        "burs": ["burs", "kredi", "Ã¶ÄŸrenim", "Ã¼cret"],
        "ogrenci_isleri": ["Ã¶ÄŸrenci iÅŸleri", "iÅŸlem", "baÅŸvuru", "belge"]
    }
    
    for topic, keywords in topics.items():
        for keyword in keywords:
            if keyword in question_lower:
                return topic
    
    return "genel"

def add_question(question, answer=None, source_file=None, source_keyword=None, topic=None):
    """Soru ekle - topic otomatik tespit"""
    if not topic:
        topic = detect_topic(question)
    
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("INSERT INTO questions (question, answer, source_file, source_keyword, topic) VALUES (?, ?, ?, ?, ?)", 
              (question, answer, source_file, source_keyword, topic))
    qid = c.lastrowid
    conn.commit()
    conn.close()
    return qid

def add_question_source(question_id, source_file):
    if not source_file or not isinstance(source_file, str) or not source_file.strip():
        return  # BoÅŸ veya geÃ§ersiz kaynak eklenmesin
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    try:
        c.execute("INSERT OR IGNORE INTO question_sources (question_id, source_file) VALUES (?, ?)", (question_id, source_file))
        conn.commit()
    except Exception as e:
        print(f"âš ï¸ add_question_source hatasÄ±: {e}")
    finally:
        conn.close()

def add_similarity(qid1, qid2, similarity):
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("INSERT INTO question_similarity (question_id_1, question_id_2, similarity) VALUES (?, ?, ?)", (qid1, qid2, similarity))
    conn.commit()
    conn.close()

def get_total_questions():
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("SELECT COUNT(*) FROM questions")
    total = c.fetchone()[0]
    conn.close()
    return total

def clear_all_questions():
    """TÃ¼m sorularÄ± ve iliÅŸkili verileri siler"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("DELETE FROM question_similarity")
    c.execute("DELETE FROM question_sources")
    c.execute("DELETE FROM questions")
    conn.commit()
    conn.close()
    print("âœ… TÃ¼m sorular temizlendi")

def clear_questions_by_period(period_type="all"):
    """SorularÄ± dÃ¶nem bazÄ±nda temizle"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    
    if period_type == "today":
        c.execute("DELETE FROM questions WHERE DATE(created_at) = DATE('now')")
        c.execute("DELETE FROM user_sessions WHERE session_date = DATE('now')")
    elif period_type == "all":
        c.execute("DELETE FROM questions")
        c.execute("DELETE FROM user_sessions")
        c.execute("DELETE FROM question_sources")
        c.execute("DELETE FROM question_similarity")
    
    conn.commit()
    affected_rows = c.rowcount
    conn.close()
    return affected_rows

def get_total_unique_questions():
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("SELECT COUNT(DISTINCT question) FROM questions")
    total = c.fetchone()[0]
    conn.close()
    return total

def get_available_filenames():
    """Mevcut dosya isimlerini enhanced_document_data.json'dan al"""
    try:
        with open("enhanced_document_data.json", "r", encoding="utf-8") as f:
            data = json.load(f)
            return [item["filename"] for item in data]
    except Exception as e:
        print(f"Enhanced document data okunamadÄ±: {e}")
        return []

def get_top_sources(limit=5):
    """Sadece mevcut dosyalardan en Ã§ok kullanÄ±lan kaynaklarÄ± al - aynÄ± dosya iÃ§in tek kayÄ±t"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    
    # Mevcut dosya isimlerini al
    available_files = get_available_filenames()
    
    if not available_files:
        conn.close()
        return [("(HiÃ§ kaynak kullanÄ±lmadÄ±)", "", 0)]
    
    # Enhanced document data'dan anahtar kelimeleri al
    try:
        with open("enhanced_document_data.json", "r", encoding="utf-8") as f:
            document_data = json.load(f)
            file_keywords = {item["filename"]: item.get("keyword", "") for item in document_data}
    except Exception as e:
        print(f"Enhanced document data okunamadÄ±: {e}")
        file_keywords = {}
    
    # Placeholder'larÄ± oluÅŸtur
    placeholders = ','.join(['?' for _ in available_files])
    
    # Her dosya iÃ§in toplam kullanÄ±m sayÄ±sÄ±nÄ± al (source_keyword'e bakmadan)
    c.execute(f"""
    SELECT source_file, COUNT(*) as cnt
    FROM questions
    WHERE source_file IS NOT NULL AND source_file != ''
    AND source_file IN ({placeholders})
    GROUP BY source_file
    ORDER BY cnt DESC
    LIMIT ?
    """, available_files + [limit])
    
    results = c.fetchall()
    conn.close()
    
    if not results:
        return [("(HiÃ§ kaynak kullanÄ±lmadÄ±)", "", 0)]
    
    # SonuÃ§larÄ± enhanced_document_data.json'dan gelen anahtar kelimelerle birleÅŸtir
    final_results = []
    for source_file, count in results:
        keyword = file_keywords.get(source_file, "")
        final_results.append((source_file, keyword, count))
    
    return final_results

def get_top_questions_by_similarity(limit=5):
    """Benzer sorularÄ± gruplar ve en Ã§ok sorulan gruplarÄ± dÃ¶ndÃ¼rÃ¼r"""
    import difflib
    from collections import defaultdict
    
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    
    # TÃ¼m sorularÄ± ve cevaplarÄ±nÄ± al
    c.execute("SELECT question, answer, COUNT(*) as cnt FROM questions GROUP BY question, answer")
    all_questions = c.fetchall()
    conn.close()
    
    if not all_questions:
        return []
    
    # Benzer sorularÄ± grupla
    question_groups = defaultdict(list)
    processed = set()
    
    for i, (question, answer, count) in enumerate(all_questions):
        if i in processed:
            continue
            
        # Bu soru iÃ§in grup oluÅŸtur
        group_key = question.lower().strip()
        group_questions = [(question, answer, count)]
        processed.add(i)
        
        # DiÄŸer sorularla benzerlik kontrolÃ¼
        for j, (other_question, other_answer, other_count) in enumerate(all_questions):
            if j in processed or i == j:
                continue
                
            # Benzerlik oranÄ±nÄ± hesapla
            similarity = difflib.SequenceMatcher(
                None, 
                question.lower().strip(), 
                other_question.lower().strip()
            ).ratio()
            
            # %75 ve Ã¼zeri benzerlik varsa aynÄ± grup
            if similarity >= 0.75:
                group_questions.append((other_question, other_answer, other_count))
                processed.add(j)
        
        # Grup toplamÄ±nÄ± hesapla
        total_count = sum(q[2] for q in group_questions)
        
        # En Ã§ok sorulan soruyu temsil edici olarak seÃ§
        representative = max(group_questions, key=lambda x: x[2])
        
        question_groups[group_key] = {
            'question': representative[0],
            'answer': representative[1], 
            'count': total_count,
            'variants': len(group_questions)
        }
    
    # SayÄ±ya gÃ¶re sÄ±rala ve limit kadar al
    sorted_groups = sorted(
        question_groups.values(), 
        key=lambda x: x['count'], 
        reverse=True
    )
    
    return [(g['question'], g['answer'], g['count']) for g in sorted_groups[:limit]]

def track_user_session(user_id, question_asked=False):
    """KullanÄ±cÄ± oturumunu takip et"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    
    today = datetime.now().date()
    
    try:
        # BugÃ¼n iÃ§in session var mÄ± kontrol et
        c.execute("""
            SELECT id, total_questions FROM user_sessions 
            WHERE user_id = ? AND session_date = ?
        """, (user_id, today))
        
        result = c.fetchone()
        
        if result:
            # Mevcut session'Ä± gÃ¼ncelle
            session_id, current_questions = result
            new_question_count = current_questions + (1 if question_asked else 0)
            
            c.execute("""
                UPDATE user_sessions 
                SET last_activity = CURRENT_TIMESTAMP, total_questions = ?
                WHERE id = ?
            """, (new_question_count, session_id))
        else:
            # Yeni session oluÅŸtur
            c.execute("""
                INSERT INTO user_sessions (user_id, session_date, total_questions)
                VALUES (?, ?, ?)
            """, (user_id, today, 1 if question_asked else 0))
        
        conn.commit()
    except Exception as e:
        print(f"Session tracking hatasÄ±: {e}")
    finally:
        conn.close()

def get_daily_user_stats():
    """GÃ¼nlÃ¼k kullanÄ±cÄ± istatistiklerini getir"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    
    try:
        # BugÃ¼nkÃ¼ aktif kullanÄ±cÄ± sayÄ±sÄ±
        c.execute("""
            SELECT COUNT(DISTINCT user_id) as daily_users
            FROM user_sessions 
            WHERE session_date = date('now')
        """)
        daily_users = c.fetchone()[0] or 0
        
        # Toplam benzersiz kullanÄ±cÄ± sayÄ±sÄ±
        c.execute("""
            SELECT COUNT(DISTINCT user_id) as total_users
            FROM user_sessions
        """)
        total_users = c.fetchone()[0] or 0
        
        # Son 7 gÃ¼nlÃ¼k aktivite
        c.execute("""
            SELECT session_date, COUNT(DISTINCT user_id) as user_count
            FROM user_sessions 
            WHERE session_date >= date('now', '-7 days')
            GROUP BY session_date 
            ORDER BY session_date DESC
        """)
        weekly_activity = c.fetchall()
        
        # BugÃ¼nkÃ¼ toplam soru sayÄ±sÄ±
        c.execute("""
            SELECT SUM(total_questions) as daily_questions
            FROM user_sessions 
            WHERE session_date = date('now')
        """)
        daily_questions = c.fetchone()[0] or 0
        
        return {
            'daily_users': daily_users,
            'total_users': total_users,
            'daily_questions': daily_questions,
            'weekly_activity': weekly_activity
        }
    except Exception as e:
        print(f"Ä°statistik hatasÄ±: {e}")
        return {
            'daily_users': 0,
            'total_users': 0, 
            'daily_questions': 0,
            'weekly_activity': []
        }
    finally:
        conn.close()

def get_total_entry_count():
    """Toplam giriÅŸ sayÄ±sÄ±nÄ± getir"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    
    try:
        c.execute("SELECT COUNT(*) as total_entries FROM user_sessions")
        result = c.fetchone()
        return result[0] if result else 0
    except Exception as e:
        print(f"Toplam giriÅŸ sayÄ±sÄ± hatasÄ±: {e}")
        return 0
    finally:
        conn.close()

def get_top_questions_with_topics(limit=5):
    """Topic'lere gÃ¶re gruplandÄ±rÄ±lmÄ±ÅŸ en Ã§ok sorulan sorularÄ± dÃ¶ndÃ¼rÃ¼r"""
    import difflib
    from collections import defaultdict
    
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    
    # TÃ¼m sorularÄ± topic ile birlikte al
    c.execute("SELECT question, answer, topic, COUNT(*) as cnt FROM questions GROUP BY question, answer, topic")
    all_questions = c.fetchall()
    conn.close()
    
    if not all_questions:
        return []
    
    # Topic'lere gÃ¶re grupla
    topic_groups = defaultdict(list)
    
    for question, answer, topic, count in all_questions:
        topic = topic or "genel"
        topic_groups[topic].append((question, answer, count))
    
    # Her topic iÃ§in benzer sorularÄ± grupla
    final_results = []
    
    for topic, questions in topic_groups.items():
        if not questions:
            continue
            
        # Bu topic iÃ§inde benzer sorularÄ± grupla
        processed = set()
        grouped_questions = []
        
        for i, (question, answer, count) in enumerate(questions):
            if i in processed:
                continue
                
            group_questions = [(question, answer, count)]
            processed.add(i)
            
            # AynÄ± topic iÃ§indeki diÄŸer sorularla benzerlik kontrolÃ¼
            for j, (other_question, other_answer, other_count) in enumerate(questions):
                if j in processed or i == j:
                    continue
                
                similarity = difflib.SequenceMatcher(
                    None, 
                    question.lower().strip(), 
                    other_question.lower().strip()
                ).ratio()
                
                if similarity >= 0.7:  # %70 benzerlik
                    group_questions.append((other_question, other_answer, other_count))
                    processed.add(j)
            
            # Grup toplamÄ±nÄ± hesapla
            total_count = sum(q[2] for q in group_questions)
            
            # En Ã§ok sorulan soruyu temsil edici seÃ§
            representative = max(group_questions, key=lambda x: x[2])
            
            grouped_questions.append({
                'question': f"[{topic.replace('_', ' ').title()}] {representative[0]}",
                'answer': representative[1],
                'count': total_count,
                'topic': topic,
                'variants': len(group_questions)
            })
        
        final_results.extend(grouped_questions)
    
    # SayÄ±ya gÃ¶re sÄ±rala ve limit kadar al
    final_results.sort(key=lambda x: x['count'], reverse=True)
    return final_results[:limit]

def clean_obsolete_sources():
    """ArtÄ±k mevcut olmayan dosyalara ait kayÄ±tlarÄ± temizle ve anahtar kelimeleri gÃ¼ncelle"""
    try:
        available_files = get_available_filenames()
        
        if not available_files:
            print("Mevcut dosya bulunamadÄ±, temizlik yapÄ±lmÄ±yor.")
            return
            
        conn = sqlite3.connect(DB_PATH)
        c = conn.cursor()
        
        # Mevcut olmayan kaynak dosyalarÄ±na sahip kayÄ±tlarÄ± bul
        placeholders = ','.join(['?' for _ in available_files])
        c.execute(f"""
        SELECT COUNT(*) FROM questions 
        WHERE source_file IS NOT NULL 
        AND source_file != '' 
        AND source_file NOT IN ({placeholders})
        """, available_files)
        
        obsolete_count = c.fetchone()[0]
        
        if obsolete_count > 0:
            print(f"Temizlenecek eski kayÄ±t sayÄ±sÄ±: {obsolete_count}")
            
            # Eski kayÄ±tlarÄ± sil
            c.execute(f"""
            DELETE FROM questions 
            WHERE source_file IS NOT NULL 
            AND source_file != '' 
            AND source_file NOT IN ({placeholders})
            """, available_files)
            
            conn.commit()
            print(f"{obsolete_count} eski kayÄ±t temizlendi.")
        else:
            print("Temizlenecek eski kayÄ±t bulunamadÄ±.")
            
        conn.close()
        
        # Anahtar kelimeleri gÃ¼ncelle
        update_missing_keywords()
        
    except Exception as e:
        print(f"Eski kayÄ±t temizlenirken hata: {e}")

def update_missing_keywords():
    """Eksik anahtar kelimeleri enhanced_document_data.json'dan gÃ¼ncelle"""
    try:
        # Enhanced document data'dan anahtar kelimeleri al
        with open("enhanced_document_data.json", "r", encoding="utf-8") as f:
            document_data = json.load(f)
            file_keywords = {item["filename"]: item.get("keyword", "") for item in document_data}
        
        conn = sqlite3.connect(DB_PATH)
        c = conn.cursor()
        
        updated_count = 0
        
        for filename, keyword in file_keywords.items():
            if keyword:  # Anahtar kelime varsa
                # Bu dosya iÃ§in boÅŸ anahtar kelimeli kayÄ±tlarÄ± gÃ¼ncelle
                c.execute("""
                UPDATE questions 
                SET source_keyword = ? 
                WHERE source_file = ? 
                AND (source_keyword IS NULL OR source_keyword = '')
                """, (keyword, filename))
                
                updated_count += c.rowcount
        
        conn.commit()
        conn.close()
        
        if updated_count > 0:
            print(f"{updated_count} kayÄ±t iÃ§in anahtar kelime gÃ¼ncellendi.")
        else:
            print("GÃ¼ncellenecek anahtar kelime bulunamadÄ±.")
            
    except Exception as e:
        print(f"Anahtar kelime gÃ¼ncellenirken hata: {e}")

def get_daily_questions_paginated(page=1, limit=10):
    """BugÃ¼n sorulan sorularÄ± sayfalayarak al - kaynak bilgileriyle birlikte"""
    try:
        conn = sqlite3.connect(DB_PATH)
        c = conn.cursor()
        
        today = datetime.now().strftime('%Y-%m-%d')
        offset = (page - 1) * limit
        
        # Enhanced document data'dan anahtar kelimeleri al
        file_keywords = {}
        try:
            with open("enhanced_document_data.json", "r", encoding="utf-8") as f:
                document_data = json.load(f)
                file_keywords = {item["filename"]: item.get("keyword", "") for item in document_data}
        except Exception as e:
            print(f"Enhanced document data okunamadÄ±: {e}")
        
        # BugÃ¼n sorulan sorular - aynÄ± sorularÄ± grupla (case-insensitive)
        c.execute("""
        SELECT LOWER(TRIM(question)) as normalized_question, 
               question as original_question,
               answer, 
               source_file,
               topic,
               COUNT(*) as count, 
               MIN(created_at) as first_asked
        FROM questions 
        WHERE DATE(created_at) = ?
        GROUP BY LOWER(TRIM(question))
        ORDER BY count DESC, first_asked DESC
        LIMIT ? OFFSET ?
        """, (today, limit, offset))
        
        questions = []
        for i, (normalized_question, original_question, answer, source_file, topic, count, created_at) in enumerate(c.fetchall()):
            source_keyword = file_keywords.get(source_file, "") if source_file else ""
            questions.append({
                "id": offset + i + 1,
                "question": original_question,
                "answer": answer,
                "count": count,
                "created_at": created_at,
                "source_file": source_file,
                "source_keyword": source_keyword,
                "topic": topic or "Genel"
            })
        
        # Toplam sayfa sayÄ±sÄ±nÄ± hesapla - unique sorular iÃ§in
        c.execute("""
        SELECT COUNT(*) as total
        FROM (
            SELECT DISTINCT LOWER(TRIM(question))
            FROM questions 
            WHERE DATE(created_at) = ?
        )
        """, (today,))
        
        total_questions = c.fetchone()[0]
        total_pages = (total_questions + limit - 1) // limit  # Ceiling division
        
        conn.close()
        
        return {
            "questions": questions,
            "total_pages": max(1, total_pages),
            "total_questions": total_questions
        }
        
    except Exception as e:
        print(f"GÃ¼nlÃ¼k sorular alÄ±nÄ±rken hata: {e}")
        return {
            "questions": [],
            "total_pages": 1,
            "total_questions": 0
        }
        
    except Exception as e:
        print(f"GÃ¼nlÃ¼k sorular alÄ±nÄ±rken hata: {e}")
        return {
            "questions": [],
            "total_pages": 1,
            "total_questions": 0
        }

def get_all_questions_paginated(page=1, limit=10):
    """TÃ¼m sorularÄ± sayfalayarak al - en Ã§ok sorulan sorular iÃ§in"""
    try:
        conn = sqlite3.connect(DB_PATH)
        c = conn.cursor()
        
        offset = (page - 1) * limit
        
        # Enhanced document data'dan anahtar kelimeleri al
        file_keywords = {}
        try:
            with open("enhanced_document_data.json", "r", encoding="utf-8") as f:
                document_data = json.load(f)
                file_keywords = {item["filename"]: item.get("keyword", "") for item in document_data}
        except Exception as e:
            print(f"Enhanced document data okunamadÄ±: {e}")
        
        # TÃ¼m sorular - aynÄ± sorularÄ± grupla (case-insensitive)
        c.execute("""
        SELECT LOWER(TRIM(question)) as normalized_question, 
               question as original_question,
               answer, 
               source_file,
               topic,
               COUNT(*) as count, 
               MIN(created_at) as first_asked
        FROM questions 
        GROUP BY LOWER(TRIM(question))
        ORDER BY count DESC, first_asked DESC
        LIMIT ? OFFSET ?
        """, (limit, offset))
        
        questions = []
        for i, (normalized_question, original_question, answer, source_file, topic, count, created_at) in enumerate(c.fetchall()):
            source_keyword = file_keywords.get(source_file, "") if source_file else ""
            questions.append({
                "id": offset + i + 1,
                "question": original_question,
                "answer": answer,
                "count": count,
                "created_at": created_at,
                "source_file": source_file,
                "source_keyword": source_keyword,
                "topic": topic or "Genel"
            })
        
        # Toplam sayfa sayÄ±sÄ±nÄ± hesapla - unique sorular iÃ§in
        c.execute("""
        SELECT COUNT(*) as total
        FROM (
            SELECT DISTINCT LOWER(TRIM(question))
            FROM questions 
        )
        """)
        
        total_questions = c.fetchone()[0]
        total_pages = (total_questions + limit - 1) // limit  # Ceiling division
        
        conn.close()
        
        return {
            "questions": questions,
            "total_pages": max(1, total_pages),
            "total_questions": total_questions
        }
        
    except Exception as e:
        print(f"TÃ¼m sorular alÄ±nÄ±rken hata: {e}")
        return {
            "questions": [],
            "total_pages": 1,
            "total_questions": 0
        }
        
    except Exception as e:
        print(f"TÃ¼m sorular alÄ±nÄ±rken hata: {e}")
        return {
            "questions": [],
            "total_pages": 1,
            "total_questions": 0
        }

if __name__ == "__main__":
    init_db()
    clear_all_questions()  # VeritabanÄ±nÄ± temizle
    print("ðŸ”„ VeritabanÄ± sÄ±fÄ±rlandÄ± ve hazÄ±r")