import chromadb
from sentence_transformers import SentenceTransformer
from quer import ask_local_llm, temizle_yanit
from config import config
from query_processor import QueryProcessor
from hybrid_retriever import HybridRetriever
from evaluator import ResponseEvaluator
import logging
import re
from typing import Dict, List, Any, Optional

# Logging setup
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class AdvancedRAGChatbot:
    """GeliÅŸmiÅŸ RAG Chatbot sistemi"""

    def __init__(self, chroma_path: str = "./chroma"):
        self.retriever = HybridRetriever(chroma_path)
        self.query_processor = QueryProcessor()
        self.evaluator = ResponseEvaluator()

        logger.info("ğŸ¤– GeliÅŸmiÅŸ RAG Chatbot baÅŸlatÄ±ldÄ±!")

    def process_query(self, user_query: str) -> Dict[str, Any]:
        """KullanÄ±cÄ± sorgusunu kapsamlÄ± ÅŸekilde iÅŸle"""
        try:
            # 1. Query preprocessing
            processed_query = self.query_processor.process_query(user_query)
            logger.info(f"ğŸ“ Ä°ÅŸlenmiÅŸ sorgu kategorisi: {processed_query['category']}")

            # 2. Advanced retrieval
            retrieval_result = self.retriever.advanced_retrieve(
                user_query, n_results=config.DEFAULT_N_RESULTS
            )

            if not retrieval_result["results"]:
                return self._handle_no_results(user_query)

            # 3. Filter by similarity threshold
            filtered_results = self.retriever.filter_by_similarity_threshold(
                retrieval_result["results"]
            )

            if not filtered_results:
                return self._handle_low_similarity(
                    user_query, retrieval_result["results"]
                )

            # 4. Context preparation
            context_info = self._prepare_context(filtered_results, processed_query)

            # 5. Generate response
            response_data = self._generate_response(
                user_query, context_info, processed_query
            )

            # 6. Evaluate response quality
            evaluation = self._evaluate_response(
                response_data["response"],
                user_query,
                context_info["sources"],
                context_info["documents"],
            )

            # 7. Prepare final result
            # Sadece gerÃ§ekten kullanÄ±lan ilk source'u dÃ¶ndÃ¼r (en yÃ¼ksek skorlu)
            result = {
                "response": response_data["response"],
                "sources": context_info["sources"][:1],  # Ä°lk source (en alakalÄ±)
                "confidence": evaluation["overall_score"],
                "quality_level": evaluation["quality_level"],
                "query_analysis": processed_query,
                "retrieval_info": {
                    "total_found": len(retrieval_result["results"]),
                    "after_filtering": len(filtered_results),
                    "best_score": (
                        filtered_results[0]["combined_score"] if filtered_results else 0
                    ),
                },
                "evaluation": evaluation,
            }

            return result

        except Exception as e:
            logger.error(f"âŒ Query iÅŸleme hatasÄ±: {e}")
            return self._handle_error(user_query, str(e))

    def _prepare_context(
        self, results: List[Dict[str, Any]], processed_query: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Retrieval sonuÃ§larÄ±ndan context hazÄ±rla"""

        context_parts = []
        sources = []  # Set yerine list - sÄ±ralamayÄ± koru
        documents = []
        user_query = processed_query.get('original_query', processed_query.get('query', ''))

        for i, result in enumerate(results[: config.DEFAULT_N_RESULTS], 1):
            doc = result["document"]
            metadata = result.get("metadata", {})
            score = result.get("combined_score", 0)

            # Document relevans kontrolÃ¼ - alakasÄ±z dÃ¶kÃ¼manlarÄ± filtrele
            if not self._is_document_relevant_to_query(doc, user_query):
                continue

            # Document preprocessing
            clean_doc = self._clean_document_for_context(doc)
            documents.append(clean_doc)

            # Source tracking - sÄ±ralÄ± ve tekrarsÄ±z
            source_file = metadata.get("source_file", f"Belge_{i}")
            if source_file not in sources:  # Duplicate check
                sources.append(source_file)

            # Context formatting
            context_parts.append(
                {
                    "index": i,
                    "content": clean_doc,
                    "source": source_file,
                    "score": score,
                    "chunk_index": metadata.get("chunk_index", 0),
                }
            )

        # Generate rich context
        formatted_context = self._format_context_for_llm(context_parts, processed_query)

        return {
            "formatted_context": formatted_context,
            "sources": sources,  # ArtÄ±k list olarak dÃ¶ndÃ¼r
            "documents": documents,
            "context_parts": context_parts,
        }

    def _clean_document_for_context(self, document: str) -> str:
        """DokÃ¼manÄ± context iÃ§in temizle"""
        # Fazla boÅŸluklarÄ± temizle
        clean_doc = " ".join(document.split())

        # Ã‡ok uzun dokÃ¼manlarÄ± kÄ±salt
        words = clean_doc.split()
        if (
            len(words) > config.MAX_CONTEXT_LENGTH // 5
        ):  # YaklaÅŸÄ±k kelime baÅŸÄ±na 5 karakter
            clean_doc = " ".join(words[: config.MAX_CONTEXT_LENGTH // 5]) + "..."

        return clean_doc

    def _is_document_relevant_to_query(self, document: str, user_query: str) -> bool:
        """DÃ¶kÃ¼manÄ±n sorguyla alakalÄ± olup olmadÄ±ÄŸÄ±nÄ± kontrol et"""
        doc_lower = document.lower()
        
        # Genel anahtar kelime kontrolÃ¼
        query_keywords = self._extract_query_keywords(user_query)
        if not query_keywords:
            return True  # Anahtar kelime yoksa tÃ¼m dÃ¶kÃ¼manlarÄ± al
            
        # En az bir anahtar kelime geÃ§meli
        keyword_matches = sum(1 for keyword in query_keywords if keyword in doc_lower)
        return keyword_matches > 0

    def _format_context_for_llm(
        self, context_parts: List[Dict[str, Any]], processed_query: Dict[str, Any]
    ) -> str:
        """LLM iÃ§in context'i formatla"""

        context_lines = []

        for part in context_parts:
            source_info = f"[{part['source']}]"
            content = part["content"]
            score_info = f"(Uygunluk: {part['score']:.2f})"

            context_lines.append(
                f"{part['index']}. {source_info} {content} {score_info}"
            )

        return "\n\n".join(context_lines)

    def _generate_response(
        self,
        user_query: str,
        context_info: Dict[str, Any],
        processed_query: Dict[str, Any],
    ) -> Dict[str, Any]:
        """GeliÅŸmiÅŸ prompt ile yanÄ±t Ã¼ret"""

        # Query kategorisine gÃ¶re Ã¶zelleÅŸtirilmiÅŸ prompt
        specialized_instructions = self._get_specialized_instructions(
            processed_query["category"]
        )

        # Tek soruya odaklanan prompt oluÅŸtur
        focused_system_prompt = config.SYSTEM_PROMPT + "\n" + specialized_instructions + """

Ã–NEMLI: Sadece kullanÄ±cÄ±nÄ±n ÅŸu anda sorduÄŸu soruya cevap ver. Ã–nceki sorular veya konularla ilgili bilgi verme.
Bu sorguya Ã¶zgÃ¼ ve kesin bir yanÄ±t ver. BaÅŸka konulara deÄŸinme."""

        # Ana prompt oluÅŸtur
        prompt = config.RAG_PROMPT_TEMPLATE.format(
            system_prompt=focused_system_prompt,
            question=user_query,
            context=context_info["formatted_context"],
        )

        # LLM'den yanÄ±t al
        raw_response = ask_local_llm(prompt, model=config.LLM_MODEL)
        clean_response = temizle_yanit(raw_response)

        # YanÄ±t post-processing - tek soruya odaklanarak
        processed_response = self._post_process_response(
            clean_response, context_info["sources"], user_query
        )

        return {
            "response": processed_response,
            "raw_response": raw_response,
            "prompt_used": prompt,
        }

    def _get_specialized_instructions(self, query_category: str) -> str:
        """Query kategorisine gÃ¶re Ã¶zel talimatlar"""
        instructions = {
            "procedure": "\nProsedÃ¼r sorularÄ±nda adÄ±m adÄ±m aÃ§Ä±klama yap. SÄ±ralÄ± iÅŸlemler ver.",
            "temporal": "\nTarih ve zaman bilgilerini kesin olarak belirt. 'yaklaÅŸÄ±k' gibi belirsiz ifadeler kullanma.",
            "quantitative": "\nSayÄ±sal bilgileri tam olarak ver. Belirsizlik varsa bunu aÃ§Ä±kÃ§a belirt.",
            "definition": "\nTanÄ±mlarÄ± net ve anlaÅŸÄ±lÄ±r ÅŸekilde yap. Ã–rnekler ver.",
            "explanation": "\nSebep-sonuÃ§ iliÅŸkilerini aÃ§Ä±kla. MantÄ±klÄ± gerekÃ§eler sun.",
            "location": "\nYer bilgilerini spesifik olarak belirt.",
            "general": "\nKapsamlÄ± ve dÃ¼zenli bir aÃ§Ä±klama yap.",
        }

        return instructions.get(query_category, instructions["general"])

    def _post_process_response(self, response: str, sources: List[str], user_query: str = None) -> str:
        """YanÄ±tÄ± son iÅŸleme tabi tut"""

        # Kaynak bilgilerini temizle - LLM'den gelen kaynak referanslarÄ±nÄ± kaldÄ±r
        import re
        
        # Daha kapsamlÄ± kaynak referansÄ± temizleme
        # "Kaynak:" ile baÅŸlayan tÃ¼m kÄ±sÄ±mlarÄ± temizle
        response = re.sub(r'\s*Kaynak:\s*\[.*?\].*?$', '', response, flags=re.IGNORECASE | re.MULTILINE)
        response = re.sub(r'\s*Kaynak:\s*.*?\.pdf.*?$', '', response, flags=re.IGNORECASE | re.MULTILINE)
        response = re.sub(r'\s*Kaynak:\s*.*?\.docx.*?$', '', response, flags=re.IGNORECASE | re.MULTILINE)
        response = re.sub(r'\s*Kaynak belge:\s*.*?$', '', response, flags=re.IGNORECASE | re.MULTILINE)
        
        # KÃ¶ÅŸeli parantez iÃ§indeki dosya referanslarÄ±nÄ± temizle
        response = re.sub(r'\s*\[.*?\.pdf\].*?$', '', response, flags=re.IGNORECASE | re.MULTILINE)
        response = re.sub(r'\s*\[.*?\.docx\].*?$', '', response, flags=re.IGNORECASE | re.MULTILINE)
        response = re.sub(r'\s*\[Anasayfa.*?\].*?$', '', response, flags=re.IGNORECASE | re.MULTILINE)
        
        # "......" ile biten kÄ±sÄ±mlarÄ± temizle
        response = re.sub(r'\.{3,}.*?$', '', response, flags=re.MULTILINE)
        
        # SatÄ±r sonundaki gereksiz boÅŸluklarÄ± temizle
        response = re.sub(r'\s+$', '', response, flags=re.MULTILINE)
        
        # Ã‡ok kÄ±sa yanÄ±tlarÄ± geniÅŸlet
        if len(response) < config.MIN_ANSWER_LENGTH:
            response += " Bu konuda daha detaylÄ± bilgi iÃ§in ilgili belgeleri inceleyebilirsiniz."

        return response.strip()

    def _filter_response_for_single_query(self, response: str, user_query: str) -> str:
        """YanÄ±tÄ± tek soruya odaklayacak ÅŸekilde filtrele"""
        
        # Ã–nce alakasÄ±z ifadeleri temizle
        response = self._remove_irrelevant_phrases(response, user_query)
        
        # EÄŸer yanÄ±t Ã§ok kÄ±sa kaldÄ±ysa, LLM'den gelen orijinal yanÄ±tÄ± kullan
        if len(response.strip()) < 50:
            return response
        
        # KullanÄ±cÄ±nÄ±n sorusundaki anahtar kelimeleri Ã§Ä±kar
        query_keywords = self._extract_query_keywords(user_query)
        
        # YanÄ±tÄ± cÃ¼mlelere bÃ¶l (nokta, Ã¼nlem, soru iÅŸaretiyle)
        sentences = re.split(r'[.!?]+', response)
        sentences = [s.strip() for s in sentences if s.strip()]  # BoÅŸ cÃ¼mleleri temizle
        
        filtered_sentences = []
        
        # Ä°lk iki cÃ¼mleyi her zaman dahil et (genellikle doÄŸru cevap)
        if sentences:
            filtered_sentences.extend(sentences[:2])
        
        # DiÄŸer cÃ¼mleleri relevans kontrolÃ¼nden geÃ§ir
        for sentence in sentences[2:]:
            if self._is_sentence_relevant_to_query(sentence, query_keywords, user_query):
                filtered_sentences.append(sentence)
            else:
                # Ä°lgisiz cÃ¼mle bulunduÄŸunda dur (Ã§oklu konu yanÄ±tÄ±nÄ± Ã¶nle)
                break
        
        # CÃ¼mleleri doÄŸru ÅŸekilde birleÅŸtir
        if filtered_sentences:
            filtered_response = '. '.join(filtered_sentences)
            if not filtered_response.endswith('.'):
                filtered_response += '.'
        else:
            filtered_response = response  # Fallback
        
        return filtered_response.strip()

    def _extract_query_keywords(self, query: str) -> list:
        """Sorgudan anahtar kelimeleri Ã§Ä±kar"""
        # TÃ¼rkÃ§e stop words
        stop_words = {'ve', 'ile', 'iÃ§in', 'de', 'da', 'bir', 'bu', 'ÅŸu', 'o', 'ben', 'sen', 'biz', 'siz', 'onlar',
                     'nasÄ±l', 'ne', 'nedir', 'kim', 'nerede', 'neden', 'niÃ§in', 'hangi', 'kaÃ§', 'ne zaman'}
        
        words = query.lower().split()
        keywords = [word for word in words if word not in stop_words and len(word) > 2]
        return keywords

    def _is_sentence_relevant_to_query(self, sentence: str, query_keywords: list, user_query: str) -> bool:
        """CÃ¼mlenin sorguyla alakalÄ± olup olmadÄ±ÄŸÄ±nÄ± kontrol et"""
        sentence_lower = sentence.lower()
        
        # Anahtar kelime match kontrolÃ¼
        keyword_matches = sum(1 for keyword in query_keywords if keyword in sentence_lower)
        
        # EÄŸer hiÃ§ anahtar kelime yoksa alakasÄ±z
        return keyword_matches > 0

    def _remove_irrelevant_phrases(self, response: str, user_query: str) -> str:
        """AlakasÄ±z ifadeleri temizle"""
        
        # Genel alakasÄ±z baÅŸlangÄ±Ã§larÄ± temizle
        irrelevant_starts = [
            r'^[^.]*belgede[^.]*kurallar[^.]*\.',
            r'^[^.]*ancak[^.]*\.',
            r'^[^.]*eÄŸer[^.]*\.'
        ]
        
        for pattern in irrelevant_starts:
            response = re.sub(pattern, '', response, flags=re.IGNORECASE)
        
        # Ã‡oklu boÅŸluklarÄ± ve nokta hatalarÄ±nÄ± dÃ¼zelt
        response = re.sub(r'\s+', ' ', response)
        response = re.sub(r'\.+', '.', response)
        response = re.sub(r'\s*\.\s*', '. ', response)
        
        # BaÅŸÄ±nda/sonunda gereksiz boÅŸluk ve nokta temizle
        response = response.strip(' .')
        
        # EÄŸer cÃ¼mle noktayla bitmiyorsa ekle
        if response and not response.endswith('.'):
            response += '.'
            
        return response

    def _evaluate_response(
        self, response: str, query: str, sources: List[str], documents: List[str]
    ) -> Dict[str, Any]:
        """YanÄ±t kalitesini deÄŸerlendir"""
        return self.evaluator.evaluate_response(response, query, sources, documents)

    def _handle_no_results(self, query: str) -> Dict[str, Any]:
        """SonuÃ§ bulunamadÄ±ÄŸÄ±nda"""
        return {
            "response": config.FALLBACK_RESPONSE,
            "sources": [],
            "confidence": 0.0,
            "quality_level": "Bilgi Yok",
            "query_analysis": self.query_processor.process_query(query),
            "retrieval_info": {"total_found": 0, "after_filtering": 0, "best_score": 0},
            "evaluation": {
                "overall_score": 0.0,
                "improvement_suggestions": ["Daha spesifik soru sorun"],
            },
        }

    def _handle_low_similarity(
        self, query: str, results: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """DÃ¼ÅŸÃ¼k benzerlik skorlarÄ±nda"""
        best_score = results[0]["combined_score"] if results else 0

        response = (
            f"Bu konuda kesin bilgi bulunamadÄ±. "
            f"En yakÄ±n benzerlik skoru: {best_score:.2f}. "
            f"Daha spesifik bir soru sormayÄ± deneyebilirsiniz."
        )

        return {
            "response": response,
            "sources": [],
            "confidence": best_score,
            "quality_level": "DÃ¼ÅŸÃ¼k GÃ¼ven",
            "query_analysis": self.query_processor.process_query(query),
            "retrieval_info": {
                "total_found": len(results),
                "after_filtering": 0,
                "best_score": best_score,
            },
            "evaluation": {
                "overall_score": 0.2,
                "improvement_suggestions": ["Sorguyu yeniden formÃ¼le edin"],
            },
        }

    def _handle_error(self, query: str, error_msg: str) -> Dict[str, Any]:
        """Hata durumunda"""
        return {
            "response": f"ÃœzgÃ¼nÃ¼m, sorunuzu iÅŸlerken bir hata oluÅŸtu: {error_msg}",
            "sources": [],
            "confidence": 0.0,
            "quality_level": "Hata",
            "error": error_msg,
            "evaluation": {"overall_score": 0.0},
        }

    def get_conversation_summary(self) -> Dict[str, Any]:
        """Conversation summary - now delegated to external conversation manager"""
        return {"total_queries": 0, "avg_confidence": 0.0, "recent_queries": []}


def run_interactive_chatbot():
    """Interaktif chatbot'u Ã§alÄ±ÅŸtÄ±r"""
    chatbot = AdvancedRAGChatbot()

    print("\nğŸ¤– GeliÅŸmiÅŸ RAG Chatbot baÅŸlatÄ±ldÄ±!")
    print("ğŸ’¡ Komutlar: 'exit' (Ã§Ä±kÄ±ÅŸ), 'history' (geÃ§miÅŸ), 'help' (yardÄ±m)\n")

    while True:
        try:
            user_input = input("KullanÄ±cÄ±: ").strip()

            if user_input.lower() in ["exit", "quit", "bye"]:
                summary = chatbot.get_conversation_summary()
                print(
                    f"\nBot: GÃ¶rÃ¼ÅŸmek Ã¼zere! Toplam {summary['total_queries']} soru sordunuz."
                )
                print(f"Ortalama gÃ¼ven skoru: {summary['avg_confidence']:.2f}")
                break

            elif user_input.lower() == "history":
                summary = chatbot.get_conversation_summary()
                print(f"\nğŸ“Š KonuÅŸma Ã–zeti:")
                print(f"Toplam soru: {summary['total_queries']}")
                print(f"Ortalama gÃ¼ven: {summary['avg_confidence']:.2f}")
                if summary["recent_queries"]:
                    print("Son sorular:", summary["recent_queries"])
                continue

            elif user_input.lower() == "help":
                print("\nğŸ”§ YardÄ±m:")
                print("- Normal sorularÄ±nÄ±zÄ± yazabilirsiniz")
                print("- 'history' komutu konuÅŸma geÃ§miÅŸini gÃ¶sterir")
                print("- 'exit' komutu chatbot'tan Ã§Ä±kar")
                print("- Daha kesin cevaplar iÃ§in spesifik sorular sorun")
                continue

            if not user_input:
                continue

            # Process query
            result = chatbot.process_query(user_input)

            # Display response
            print(f"\nBot: {result['response']}")

            # Display quality info (opsiyonel)
            print(
                f"\nğŸ“Š GÃ¼ven: {result['confidence']:.2f} | Kalite: {result['quality_level']}"
            )
            if result.get("sources"):
                print(f"ğŸ“š Kaynaklar: {', '.join(result['sources'][:3])}")

            print()  # BoÅŸ satÄ±r

        except KeyboardInterrupt:
            print("\nBot: GÃ¶rÃ¼ÅŸmek Ã¼zere!")
            break
        except Exception as e:
            print(f"âš ï¸ Hata oluÅŸtu: {e}")
            continue


if __name__ == "__main__":
    run_interactive_chatbot()


def get_answer(question: str) -> str:
    """Basit API fonksiyonu - batch_ask.py iÃ§in"""
    try:
        chatbot = AdvancedRAGChatbot()
        result = chatbot.process_query(question)
        
        # Kaynak bilgisini ekle
        response = result['response']
        if result.get('sources'):
            sources = ', '.join(result['sources'][:2])  # Ä°lk 2 kaynaÄŸÄ± al
            response += f"\n\nKullanÄ±lan kaynak: {sources}"
        
        return response
    except Exception as e:
        return f"Hata oluÅŸtu: {str(e)}"